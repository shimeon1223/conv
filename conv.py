# -*- coding: utf-8 -*-
"""conv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vka722G0Ngg2JOFxOLU0tZjZjYB-JCfv
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.python.keras.layers import Dense
from keras.layers import Input, Dense


class MyCNNModel(keras.Model):
    def __init__(self, num_classes):
        super(MyCNNModel, self).__init__()
        self.num_classes = num_classes
        
        self.conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation="relu")
        self.maxpool1 = layers.MaxPooling2D(pool_size=(2, 2))
        self.conv2 = layers.Conv2D(64, kernel_size=(3, 3), activation="relu")
        self.maxpool2 = layers.MaxPooling2D(pool_size=(2, 2))
        self.flatten = layers.Flatten()
        self.dropout = layers.Dropout(0.5)
        self.dense = layers.Dense(num_classes, activation="softmax")
        
    def call(self, inputs):
        x = self.conv1(inputs)
        print("conv1 output shape:", x.shape)
        x = self.maxpool1(x)
        print("maxpool1 output shape:", x.shape)
        x = self.conv2(x)
        print("conv2 output shape:", x.shape)
        x = self.maxpool2(x)
        print("maxpool2 output shape:", x.shape)
        x = self.flatten(x)
        print("flatten output shape:", x.shape)
        x = self.dropout(x)
        print("dropout output shape:", x.shape)
        outputs = self.dense(x)
        print("dense output shape:", outputs.shape)
        return outputs

# CIFAR-10データセットの読み込み
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

# データの正規化
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

# クラスの数
num_classes = 10

# モデルの構築
model = MyCNNModel(num_classes)

# モデルのコンパイル
model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

# モデルの学習
#model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=0.1)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# モデルの学習
history = model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=0.1)

# モデルの評価
score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

# エポックごとの損失と精度の推移を取得
train_loss = history.history['loss']
val_loss = history.history['val_loss']
train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

# グラフの表示
plt.figure(figsize=(8, 6))
plt.plot(range(1, len(train_loss)+1), train_loss, label='Training Loss')
plt.plot(range(1, len(val_loss)+1), val_loss, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

plt.figure(figsize=(8, 6))
plt.plot(range(1, len(train_acc)+1), train_acc, label='Training Accuracy')
plt.plot(range(1, len(val_acc)+1), val_acc, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

#活性化関数を定義、適用
class MyCNNModel1(keras.Model):
    def __init__(self, num_classes):
        super(MyCNNModel1, self).__init__()
        self.num_classes = num_classes
        
        self.conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation="relu")
        self.maxpool1 = layers.MaxPooling2D(pool_size=(2, 2))
        self.conv2 = layers.Conv2D(64, kernel_size=(3, 3), activation="relu")
        self.maxpool2 = layers.MaxPooling2D(pool_size=(2, 2))
        self.flatten = layers.Flatten()
        self.dropout = layers.Dropout(0.5)
        self.dense = layers.Dense(num_classes, activation="softmax")

    def softplus_activation(self, x):
        return tf.math.log(1.0 + tf.exp(x))    
        
    def call(self, inputs):
        x = self.conv1(inputs)
        print("conv1 output shape:", x.shape)
        x = self.maxpool1(x)
        print("maxpool1 output shape:", x.shape)
        x = self.conv2(x)
        print("conv2 output shape:", x.shape)
        x = self.maxpool2(x)
        print("maxpool2 output shape:", x.shape)
        x = self.flatten(x)
        print("flatten output shape:", x.shape)
        x = self.dropout(x)
        print("dropout output shape:", x.shape)
        x = self.dense(x)
        print("dense output shape:", x.shape)
        outputs = self.softplus_activation(x)
        print("softplus output shape:", outputs.shape)
        return outputs

# CIFAR-10データセットの読み込み
(x_train1, y_train1), (x_test1, y_test1) = keras.datasets.cifar10.load_data()

# データの正規化
x_train1 = x_train1.astype("float32") / 255.0
x_test1 = x_test1.astype("float32") / 255.0

# クラスの数
num_classes = 10

# モデルの構築
model = MyCNNModel1(num_classes)

# モデルのコンパイル
model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

# モデルの学習
history1 = model.fit(x_train1, y_train1, batch_size=64, epochs=10, validation_split=0.1)

# モデルの評価
score = model.evaluate(x_test1, y_test1, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

# エポックごとの損失と精度の推移を取得
train_loss = history1.history['loss']
val_loss = history1.history['val_loss']
train_acc = history1.history['accuracy']
val_acc = history1.history['val_accuracy']

# グラフの表示
plt.figure(figsize=(8, 6))
plt.plot(range(1, len(train_loss)+1), train_loss, label='Training Loss')
plt.plot(range(1, len(val_loss)+1), val_loss, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

plt.figure(figsize=(8, 6))
plt.plot(range(1, len(train_acc)+1), train_acc, label='Training Accuracy')
plt.plot(range(1, len(val_acc)+1), val_acc, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

